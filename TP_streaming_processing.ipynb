{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Flotauv/Projet_Git/blob/master/TP_streaming_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cba5f695-8b35-4d19-aa8d-8001fa72ba87"
      },
      "source": [
        "# TP March 2024\n",
        "\n",
        "In this section, we are going to process the streaming data about\n",
        "restaurants. But before to run this script you should run the script\n",
        "\\`TP<sub>streamingsource</sub>.ipynb\\` to start the streaming data."
      ],
      "id": "cba5f695-8b35-4d19-aa8d-8001fa72ba87"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "030b22bc-db65-4101-aba6-89aaec0c6d35"
      },
      "outputs": [],
      "source": [
        "#!pip install pyspark\n"
      ],
      "id": "030b22bc-db65-4101-aba6-89aaec0c6d35"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfOX2dWtS5Y2",
        "outputId": "03d72554-998a-4dcc-d424-9dba86b1d70a"
      },
      "id": "RfOX2dWtS5Y2",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "50022d9f-9fc1-4852-af5a-4c3ebbdfd9a8"
      },
      "outputs": [],
      "source": [
        "root_path = \"/content/drive/MyDrive/Colab Notebooks\"\n"
      ],
      "id": "50022d9f-9fc1-4852-af5a-4c3ebbdfd9a8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1246bfa-ef6b-4614-9b6f-b14423006002"
      },
      "source": [
        "# Processing the streaming data"
      ],
      "id": "a1246bfa-ef6b-4614-9b6f-b14423006002"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6e60690f-6623-4285-af05-f91f2de6e6be"
      },
      "outputs": [],
      "source": [
        "  from pyspark.sql import SparkSession\n",
        "  from pyspark.sql.types import StructType\n",
        "\n",
        "  # Initialize Spark Session\n",
        "  spark = SparkSession \\\n",
        "  .builder \\\n",
        "  .appName(\"JsonStreamingSimulation\") \\\n",
        "  .getOrCreate()\n",
        "# To allow automatic schemaInference while reading\n",
        "  spark.conf.set(\"spark.sql.streaming.schemaInference\", True)\n",
        "\n",
        "  # Define the schema (optional, for optimization)\n",
        "  #schema = StructType([...])  # Define your schema according to the JSON structure\n",
        "\n",
        "  #from pyspark.sql.types import StructType, StructField, StringType\n",
        "\n",
        "  # Read streamed data\n",
        "  json_df = spark \\\n",
        "  .readStream \\\n",
        "  .option(\"maxFilesPerTrigger\", 1) \\\n",
        "  .json(root_path + '/json_files_streamed')\n",
        "\n",
        "\n",
        "  # Processing the data into a table (e.g., displaying it on memory for demo)\n",
        "  dataStreamWriter = (json_df\n",
        "  .writeStream\n",
        "  .queryName(\"streamed_table\")\n",
        "  .outputMode(\"append\")\n",
        "  .format(\"memory\"))\n",
        "\n",
        "  #query.awaitTermination()\n",
        "  query = dataStreamWriter.start()\n",
        "\n"
      ],
      "id": "6e60690f-6623-4285-af05-f91f2de6e6be"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34c84887-e4c9-4c8c-b42e-11181949d900"
      },
      "source": [
        "# Reviewing streaming process status"
      ],
      "id": "34c84887-e4c9-4c8c-b42e-11181949d900"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b33bae9-969b-477f-847a-2a01c039371c",
        "outputId": "1ca447e6-6814-4fca-971c-545d3bb54f71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'message': 'Getting offsets from FileStreamSource[file:/content/drive/MyDrive/Colab Notebooks/json_files_streamed]', 'isDataAvailable': True, 'isTriggerActive': True}\n"
          ]
        }
      ],
      "source": [
        "print(query.status)\n"
      ],
      "id": "4b33bae9-969b-477f-847a-2a01c039371c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "672a183b-215a-41a4-9b8c-5bbb61c7c9c6"
      },
      "source": [
        "# Printing the schema of the streamed json data"
      ],
      "id": "672a183b-215a-41a4-9b8c-5bbb61c7c9c6"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f466c99-3611-4a4e-a0ac-c7b97e9c60da",
        "outputId": "4e58b539-6f08-4791-eb8c-430eb41a48c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- building: string (nullable = true)\n",
            " |    |-- coord: struct (nullable = true)\n",
            " |    |    |-- coordinates: array (nullable = true)\n",
            " |    |    |    |-- element: double (containsNull = true)\n",
            " |    |    |-- type: string (nullable = true)\n",
            " |    |-- street: string (nullable = true)\n",
            " |    |-- zipcode: string (nullable = true)\n",
            " |-- borough: string (nullable = true)\n",
            " |-- cuisine: string (nullable = true)\n",
            " |-- grades: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- date: struct (nullable = true)\n",
            " |    |    |    |-- $date: long (nullable = true)\n",
            " |    |    |-- grade: string (nullable = true)\n",
            " |    |    |-- score: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- restaurant_id: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "json_df.printSchema()\n"
      ],
      "id": "3f466c99-3611-4a4e-a0ac-c7b97e9c60da"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2e8111e-a9f9-46e1-9be3-2a8c69bc1af5"
      },
      "source": [
        "# Printing the schema of the SQL table where data is stored"
      ],
      "id": "d2e8111e-a9f9-46e1-9be3-2a8c69bc1af5"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb4fce58-8445-4aec-9a8e-4b4fc2b6b548",
        "outputId": "e43c7034-1c29-46ce-8532-e9a64b273404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------------+-------+\n",
            "|     col_name|           data_type|comment|\n",
            "+-------------+--------------------+-------+\n",
            "|      address|struct<building:s...|   NULL|\n",
            "|      borough|              string|   NULL|\n",
            "|      cuisine|              string|   NULL|\n",
            "|       grades|array<struct<date...|   NULL|\n",
            "|         name|              string|   NULL|\n",
            "|restaurant_id|              string|   NULL|\n",
            "+-------------+--------------------+-------+\n",
            "\n",
            "<class 'NoneType'>\n"
          ]
        }
      ],
      "source": [
        "describe=spark.sql(\"DESCRIBE EXTENDED streamed_table\").show(20)\n",
        "\n",
        "print(type(describe))"
      ],
      "id": "bb4fce58-8445-4aec-9a8e-4b4fc2b6b548"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a146133-cb88-4d86-8ab5-4421ba5f4825"
      },
      "source": [
        "To visualize the schema better, we convert the streamed table\n",
        "\\`streamed<sub>table</sub>\\` into a streamed dataframe \\`df\\`"
      ],
      "id": "3a146133-cb88-4d86-8ab5-4421ba5f4825"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79666076-ae56-47c2-a0bc-d25033d0e34a",
        "outputId": "ec9618d3-c0c9-4c5b-e5a0-fa82caa61472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- building: string (nullable = true)\n",
            " |    |-- coord: struct (nullable = true)\n",
            " |    |    |-- coordinates: array (nullable = true)\n",
            " |    |    |    |-- element: double (containsNull = true)\n",
            " |    |    |-- type: string (nullable = true)\n",
            " |    |-- street: string (nullable = true)\n",
            " |    |-- zipcode: string (nullable = true)\n",
            " |-- borough: string (nullable = true)\n",
            " |-- cuisine: string (nullable = true)\n",
            " |-- grades: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- date: struct (nullable = true)\n",
            " |    |    |    |-- $date: long (nullable = true)\n",
            " |    |    |-- grade: string (nullable = true)\n",
            " |    |    |-- score: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- restaurant_id: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.table(\"streamed_table\")\n",
        "df.printSchema()\n"
      ],
      "id": "79666076-ae56-47c2-a0bc-d25033d0e34a"
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FwTmJ20Vv6x",
        "outputId": "eb4d53c8-7d86-47ab-9853-88aba7711f8e"
      },
      "id": "6FwTmJ20Vv6x",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f6e471d-64ee-4b77-aeec-fcdaa3479052"
      },
      "source": [
        "# Printing the data stored in the SQL table"
      ],
      "id": "5f6e471d-64ee-4b77-aeec-fcdaa3479052"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f277af2f-b1d3-4534-8049-51a0498d20a4",
        "outputId": "48fd9e2b-dc5f-45c4-eff3-492f51156b8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------+-------+------+--------------------+-------------+\n",
            "|             address|      borough|cuisine|grades|                name|restaurant_id|\n",
            "+--------------------+-------------+-------+------+--------------------+-------------+\n",
            "|{4028, {[-73.8299...|       Queens|  Other|    []|                    |     50018982|\n",
            "|{13542, {[-73.830...|       Queens|  Other|    []|                    |     50018984|\n",
            "|{971, {[-73.96461...|    Manhattan|  Other|    []|              Subway|     50018987|\n",
            "|{325, {[-73.99514...|    Manhattan|  Other|    []|Fairfield Inn Sui...|     50018989|\n",
            "|{399, {[-73.90643...|     Brooklyn|  Other|    []|                    |     50018993|\n",
            "|{461, {[-74.13849...|Staten Island|  Other|    []|         Indian Oven|     50018994|\n",
            "|{921, {[-73.96913...|     Brooklyn|  Other|    []|        Cold Press'D|     50018995|\n",
            "|{190, {[-73.94547...|     Brooklyn|  Other|    []|    Northside Bakery|     50018952|\n",
            "|{307, {[-74.14538...|Staten Island|  Other|    []|Christine'S Resta...|     50018953|\n",
            "|{6635, {[-73.8977...|       Queens|  Other|    []|                    |     50018956|\n",
            "+--------------------+-------------+-------+------+--------------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Now you can query the in-memory table\n",
        "result_df = spark.sql(\"SELECT * FROM streamed_table LIMIT 10\")\n",
        "result_df.show(10)\n",
        "\n"
      ],
      "id": "f277af2f-b1d3-4534-8049-51a0498d20a4"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AR8JCnRdZa4p"
      },
      "id": "AR8JCnRdZa4p",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e273d2ba-779f-42e9-84ff-f86159aada1b"
      },
      "source": [
        "# Tasks\n",
        "\n",
        "## Task 1\n",
        "\n",
        "Generate a dataframe called \\`transformed<sub>df</sub>\\` from the\n",
        "streamed dataframe \\`df\\`. Use the grades to generate a table of 5\n",
        "columns (restaurant<sub>id</sub>, name, date, grade, score). Review the\n",
        "outputted table of the \\`Exercise 7\\`from the TD2. You can ask to\n",
        "ChatGPT4 or Mixtral to generate at least three solutions. Explain the\n",
        "solutions.\n",
        "\n",
        "## Task 2\n",
        "\n",
        "This a solution to the Task 1. Explain how it works."
      ],
      "id": "e273d2ba-779f-42e9-84ff-f86159aada1b"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, explode\n",
        "from pyspark.sql.functions import from_unixtime"
      ],
      "metadata": {
        "id": "s4GMU5UMnwkE"
      },
      "id": "s4GMU5UMnwkE",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51d06b7d-e82c-4c07-b2f8-1de9f17a3b2a",
        "outputId": "3785d4df-61e3-454a-d676-35ad1981ed1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------------+----------+--------------+-----+\n",
            "|restaurant_id|                name|      date|         grade|score|\n",
            "+-------------+--------------------+----------+--------------+-----+\n",
            "|     50018344|Las Qrquideas Res...|2015-01-20|Not Yet Graded|    2|\n",
            "|     50017941|           Chez Alex|2015-01-20|Not Yet Graded|   30|\n",
            "|     50018174|     Birdbath Spring|2015-01-20|Not Yet Graded|    9|\n",
            "|     50018254|           M&J Pizza|2015-01-20|Not Yet Graded|   22|\n",
            "|     50018661|      Angebienvendia|2015-01-20|Not Yet Graded|    2|\n",
            "|     50018283|M & K Spanish Res...|2015-01-20|Not Yet Graded|    2|\n",
            "|     50018173|            Cha Lait|2015-01-20|Not Yet Graded|    2|\n",
            "|     50018587|          Elk Coffee|2015-01-20|Not Yet Graded|    2|\n",
            "|     50018376| Ab Halal Restaurant|2015-01-20|Not Yet Graded|   58|\n",
            "|     50018289|      Gui Lin Mi Fen|2015-01-20|Not Yet Graded|   12|\n",
            "+-------------+--------------------+----------+--------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, explode\n",
        "\n",
        "# Assuming 'df' is the DataFrame where the JSON was initially written\n",
        "\n",
        "# If the grades array is nested inside the address, you'd use a select statement like this:\n",
        "transformed_df = df.select(\n",
        "    col('restaurant_id'),\n",
        "    col('name'),\n",
        "    explode(col('grades')).alias('grades_flat')\n",
        ").select(\n",
        "    'restaurant_id',\n",
        "    'name',\n",
        "    col('grades_flat.date.$date').alias('date'),\n",
        "    col('grades_flat.grade').alias('grade'),\n",
        "    col('grades_flat.score').alias('score')\n",
        ")\n",
        "\n",
        "# To format the date properly as shown in the image, we would use the from_unixtime function:\n",
        "from pyspark.sql.functions import from_unixtime\n",
        "\n",
        "transformed_df = transformed_df.withColumn(\n",
        "    'date', from_unixtime(col('date') / 1000, 'yyyy-MM-dd')\n",
        ")\n",
        "\n",
        "# Show the resulting DataFrame\n",
        "#transformed_df.show(10)\n",
        "transformed_df.sort(col(\"date\").desc()).show(10)\n",
        "\n"
      ],
      "id": "51d06b7d-e82c-4c07-b2f8-1de9f17a3b2a"
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_df.createOrReplaceTempView(\"transformed_df_view\")\n"
      ],
      "metadata": {
        "id": "tjePMsnGvMBj"
      },
      "id": "tjePMsnGvMBj",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a946289-7477-4cbd-a3c2-b3e0034e460a"
      },
      "source": [
        "## Task 3\n",
        "\n",
        "The Michelin group wants to award the best restaurant with a Star. A\n",
        "Michelin Star recognizes restaurants for exceptional cooking. It\n",
        "considers ingredient quality, flavor harmony, technique mastery, chef's\n",
        "personality in cuisine, and consistency across the menu and over time.\n",
        "The manager of the group asks you to find the best(s) restaurant from\n",
        "the streaming data. Is it possible? If you answer is yes, what would be\n",
        "your data query strategy to fulfill the request?\n",
        "\n",
        "-   Explain the steps of the strategy and write the corresponding query\n",
        "    for each step. Use the sample operations from Exercise 8 in TD2.\n",
        "\n",
        "The sample operations were:\n",
        "\n",
        "-   Filtering rows where the grade is 'A'"
      ],
      "id": "7a946289-7477-4cbd-a3c2-b3e0034e460a"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iHmgKAU_woFA"
      },
      "id": "iHmgKAU_woFA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "58b08e5e-2fba-40b8-a8dd-0b13048aaf42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e75ec0-a209-471d-90d6-08b8e7967816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------------+----------+-----+-----+\n",
            "|restaurant_id|                name|      date|grade|score|\n",
            "+-------------+--------------------+----------+-----+-----+\n",
            "|     50018581|            Pad Thai|2015-01-08|    A|    5|\n",
            "|     50018324|   Shelley'S Kitchen|2015-01-16|    A|   13|\n",
            "|     50018608|Trini Delite Roti...|2015-01-15|    A|   12|\n",
            "|     50018555|              Carvel|2014-12-31|    A|   11|\n",
            "|     50018266|       Sun'S Kitchen|2014-12-17|    A|    3|\n",
            "+-------------+--------------------+----------+-----+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df1 = transformed_df.filter(transformed_df['grade'] == 'A')\n",
        "df1.show(5)\n"
      ],
      "id": "58b08e5e-2fba-40b8-a8dd-0b13048aaf42"
    },
    {
      "cell_type": "code",
      "source": [
        "df_1_grade_A=spark.sql(\"SELECT * FROM transformed_df_view WHERE grade='A' \")\n",
        "\n",
        "df_1_grade_A.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUwcUiRuvepA",
        "outputId": "f7b31db1-c40d-4ac7-a96e-d1deb52c9387"
      },
      "id": "gUwcUiRuvepA",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------------+----------+-----+-----+\n",
            "|restaurant_id|                name|      date|grade|score|\n",
            "+-------------+--------------------+----------+-----+-----+\n",
            "|     50018581|            Pad Thai|2015-01-08|    A|    5|\n",
            "|     50018324|   Shelley'S Kitchen|2015-01-16|    A|   13|\n",
            "|     50018608|Trini Delite Roti...|2015-01-15|    A|   12|\n",
            "|     50018555|              Carvel|2014-12-31|    A|   11|\n",
            "|     50018266|       Sun'S Kitchen|2014-12-17|    A|    3|\n",
            "+-------------+--------------------+----------+-----+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3440dffc-ae32-4ddc-8dfa-1b8f09945772"
      },
      "source": [
        "-   Where clause to select records after a specific date:"
      ],
      "id": "3440dffc-ae32-4ddc-8dfa-1b8f09945772"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "43ce43f4-60c9-4887-9a34-025092f5a408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a0a9052-91b7-4d76-e01e-b1f853b90bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------------+----------+--------------+-----+\n",
            "|restaurant_id|                name|      date|         grade|score|\n",
            "+-------------+--------------------+----------+--------------+-----+\n",
            "|     50018754|El Coral Deli Res...|2015-01-20|Not Yet Graded|    3|\n",
            "|     50018661|      Angebienvendia|2015-01-20|Not Yet Graded|    2|\n",
            "|     50018581|            Pad Thai|2015-01-08|             A|    5|\n",
            "|     50018468|      Savour Sichuan|2015-01-20|Not Yet Graded|   56|\n",
            "|     50018480|          ''W'' Cafe|2015-01-20|Not Yet Graded|   43|\n",
            "+-------------+--------------------+----------+--------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        " from pyspark.sql.functions import to_date\n",
        "df1 = transformed_df.where(to_date(transformed_df['date'], 'yyyy-MM-dd') > '2014-01-01')\n",
        "df1.show(5)\n",
        "\n"
      ],
      "id": "43ce43f4-60c9-4887-9a34-025092f5a408"
    },
    {
      "cell_type": "code",
      "source": [
        "df1_sql=spark.sql(\"SELECT * FROM transformed_df_view WHERE  date >'2014-01-01'\")\n",
        "\n",
        "df1_sql.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH7exnmruZ5D",
        "outputId": "30f3f963-dda5-44b0-dbee-efbf58765a0a"
      },
      "id": "YH7exnmruZ5D",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------------+----------+--------------+-----+\n",
            "|restaurant_id|                name|      date|         grade|score|\n",
            "+-------------+--------------------+----------+--------------+-----+\n",
            "|     50018754|El Coral Deli Res...|2015-01-20|Not Yet Graded|    3|\n",
            "|     50018661|      Angebienvendia|2015-01-20|Not Yet Graded|    2|\n",
            "|     50018581|            Pad Thai|2015-01-08|             A|    5|\n",
            "|     50018468|      Savour Sichuan|2015-01-20|Not Yet Graded|   56|\n",
            "|     50018480|          ''W'' Cafe|2015-01-20|Not Yet Graded|   43|\n",
            "+-------------+--------------------+----------+--------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "726a357a-8fa7-4c35-a873-bc98179be4d7"
      },
      "source": [
        "-   Aggregating to find the average score for each restaurant:"
      ],
      "id": "726a357a-8fa7-4c35-a873-bc98179be4d7"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "3c59cbf1-9580-416c-9d0d-6f7aac98e03f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6e03ca-83f2-45e8-a296-e055736747ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------+\n",
            "|restaurant_id|avg_score|\n",
            "+-------------+---------+\n",
            "|     50018404|     23.0|\n",
            "|     50018376|     58.0|\n",
            "|     50018318|     20.0|\n",
            "|     50018344|      2.0|\n",
            "|     50018355|      0.0|\n",
            "+-------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        " from pyspark.sql import functions as F\n",
        " df1 = transformed_df.groupBy('restaurant_id').agg(F.avg('score').alias('avg_score'))\n",
        "df1.show(5)\n",
        "\n"
      ],
      "id": "3c59cbf1-9580-416c-9d0d-6f7aac98e03f"
    },
    {
      "cell_type": "code",
      "source": [
        "df1_sql_avg=spark.sql(\"SELECT restaurant_id, MEAN(score) as avg_score FROM transformed_df_view GROUP BY restaurant_id\")\n",
        "\n",
        "df1_sql_avg.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4Wl4lxQx4EA",
        "outputId": "9acff0dd-d658-4b5a-fec5-f4f9bfe86089"
      },
      "id": "x4Wl4lxQx4EA",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------+\n",
            "|restaurant_id|avg_score|\n",
            "+-------------+---------+\n",
            "|     50018404|     23.0|\n",
            "|     50018376|     58.0|\n",
            "|     50018318|     20.0|\n",
            "|     50018344|      2.0|\n",
            "|     50018355|      0.0|\n",
            "+-------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e771140d-37d1-4b39-b894-a58ca4da9ca5"
      },
      "source": [
        "-   Using regexp<sub>replace</sub> to clean up restaurant names: The\n",
        "    F.regexp<sub>replace</sub> function replaces every \\[ or \\] found in\n",
        "    the name column with an empty string '', effectively removing these\n",
        "    characters from the string."
      ],
      "id": "e771140d-37d1-4b39-b894-a58ca4da9ca5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8df7029c-ebe5-4908-9bf7-bedb5d7726bf"
      },
      "outputs": [],
      "source": [
        "df1 = grades_table_df.withColumn('name_clean', F.regexp_replace('name', r'(\\[|\\])', ''))\n",
        "df1.show(5)\n",
        "\n"
      ],
      "id": "8df7029c-ebe5-4908-9bf7-bedb5d7726bf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79f6c6d3-e70d-4f51-90c6-a0e61f0b3efb"
      },
      "source": [
        "-   Applying conditional logic with when to create a new\n",
        "    'score<sub>category</sub>' column"
      ],
      "id": "79f6c6d3-e70d-4f51-90c6-a0e61f0b3efb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac875428-fc02-4b4a-9a44-be5ead93c1a8"
      },
      "outputs": [],
      "source": [
        " df1 = grades_table_df.withColumn('score_category', F.when(grades_table_df['score'] < 10, 'Low')\n",
        "                                               .when(grades_table_df['score'] < 13, 'Medium')\n",
        "                                               .otherwise('High'))\n",
        "df1.show(5)\n",
        "\n"
      ],
      "id": "ac875428-fc02-4b4a-9a44-be5ead93c1a8"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  }
}